# -*- coding: utf-8 -*-
"""Tecnoap-Evaluacion.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tWDX9_rMoElDM4ICChhLBa6UsLyuyEFg
"""

# Importar librerias a utilizar
import numpy as np
import sklearn
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
from scipy import stats

# pd.set_option('display.float_format', lambda x: '%0.4f' % x)

# Cargar la informacion de los archivos Faults.train y Faults.test

data_train = pd.read_csv('Faults.train', delimiter='\t')
data_test = pd.read_csv('Faults.test', delimiter='\t')

"""# Información que sabemos a priori del dataset TRAIN 

1.   Tiene 27 atributos/variables independientes
2.   Tiene 7 clases/variables dependientes
3.   Registro de 1455 observaciones



## Información que sabemos a priori del dataset TEST 

1.   Tiene 27 atributos/variables independientes
2.   Registro de 485 observaciones


## Clases que se tienen registradas:

*   Pastry
*   Z_Scratch
*   K_Scatch
*	  Stains
*	  Dirtiness
*	  Bumps
*  	Other_Faults

# Data Exploration & Cleaning
"""

# Conocer el tamaño de Faults.train y Faults.test

print(data_train.shape)
print(data_test.shape)

# Visualizamos las columnas que conforman TRAIN
data_train.columns

# Visualizamos las columnas que conforman TEST
data_test.columns

# Conocer el tipo de dato de origen de cada columna en TRAIN
data_train.info()

# Conocer el tipo de dato de origen de cada columna en TEST
data_test.info()

"""Al ejecutar la accion "info()", nos da detalles del tipo de dato que se encuentra en cada columna. Ademas, *"non-null"* ya nos indica que no hay informacion faltante, missing data. En este sentido indica que existe un valor en cada celda. Sin embargo, si hay algun valor de relleno para representar datos que faltan, eso no sería evidente aquí."""

# Conocer como son los datos, tomamos las primeras 5 observaciones de TRAIN
data_train.head(5)

# Conocer como son los datos, tomamos las primeras 5 observaciones de TEST
data_test.head(5)

"""## Rango de las variables"""

# Rango de las Variables en TRAIN
rango_TRAIN = pd.DataFrame()
# rango_TRAIN= pd.DataFrame(data=data_train.max()-data_train.min(), columns=['Rango'])
rango_TRAIN['Maximo'] = data_train.max()
rango_TRAIN['Minimo'] = data_train.min()
rango_TRAIN['Rango'] = data_train.max()-data_train.min()
rango_TRAIN

"""* *Variables Categoricas*: TypeOfSteel_A300, TypeOfSteel_A400, Pastry, Z_Scratch,	K_Scatch,	Stains,	Dirtiness,	Bumps,	Other_Faults

* *Variables Numericas*: X_Minimum,	X_Maximum,	Y_Minimum,	Y_Maximum,	Pixels_Areas,	X_Perimeter,	Y_Perimeter,	Sum_of_Luminosity,	Minimum_of_Luminosity,	Maximum_of_Luminosity,	Length_of_Conveyer, Steel_Plate_Thickness,	Edges_Index,	Empty_Index,	Square_Index,	Outside_X_Index,	Edges_X_Index,	Edges_Y_Index, LogOfAreas,	Log_X_Index,	Log_Y_Index,	Orientation_Index,	Luminosity_Index,	SigmoidOfAreas,

## Frecuencia de las variables categoricas
"""

# Obtener la Frecuencia en que aparecen los datos en las variables categoricas
# data_train['Y_Maximum'].describe()
print("TypeOfSteel_A300:\n",data_train['TypeOfSteel_A300'].value_counts(),"\n")   # <- value_counts() Regresa en orden descendente, el primer valor es el que mas se repite
print("TypeOfSteel_A400:\n",data_train['TypeOfSteel_A400'].value_counts(),"\n")

plt.figure(figsize=(22,8))
plt.hist(data_train['TypeOfSteel_A300'])
plt.xlabel(xlabel='TypeOfSteel_A300', fontsize=16)
plt.ylabel(ylabel='Frecuencia', fontsize=16)
plt.title('Histograma de TypeOfSteel_A300', fontsize=20)
plt.show()

plt.figure(figsize=(22,8))
plt.hist(data_train['TypeOfSteel_A400'])
plt.xlabel(xlabel='TypeOfSteel_A400', fontsize=16)
plt.ylabel(ylabel='Frecuencia', fontsize=16)
plt.title('Histograma de TypeOfSteel_A400', fontsize=20)
plt.show()

"""## Missing data"""

# Buscamos si exiten campos que tengan valores nulos en TRAIN
data_train.isnull().sum()

# Buscamos si exiten campos que tengan valores nulos en TEST
data_test.isnull().sum()

# Buscar filas duplicadas en TRAIN y TEST
print(data_train[data_train.duplicated()])
print(data_test[data_test.duplicated()])

# Buscamos valores que pudieran rellenar los datos, en caso de algun faltante, por ejemplo X_Minimun es de tipo int,
# pero si fuera de tipo Object, entonces pudeira existir alguna cadena con informacion de relleno
data_train['Unnamed: 0'].value_counts()

"""## Labels

Dentro del dataset, tenemos una columna llamada por default "Unnamed: 0". En esta hay valores enteros que no llevan un orden, comprobamos que quieren expresar estos datos
"""

#Identificamos si los datos vienen etiquetados
data_train['Unnamed: 0'].nunique()

"""Tenemos como resultado 1455 valores unicos, esto es el tamaño total de instancias en el dataset TRAIN, sin embargo estos numeros no muestran un orden."""

# Buscamos si existiera algun valor repetido en esta columna
data_train['Unnamed: 0'].value_counts().head()

# Conocer cuantas instancias pertenece a cada clase.
data_train[['Pastry', 'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults']].value_counts()

"""## Histogramas"""

import matplotlib as mpl
mpl.rcParams['figure.dpi'] = 150 # cambiamos la resolucion de las figuras
# mpl.rcParams['font.size'] = 10 # cambiamos la resolucion de las figuras

data_train[['X_Minimum', 'X_Maximum']].hist()

data_train[['Y_Minimum', 'Y_Maximum']].hist()

data_train[['Pixels_Areas']].hist()

data_train[['X_Perimeter', 'Y_Perimeter']].hist()

data_train[['Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Sum_of_Luminosity']].hist()

data_train[['Length_of_Conveyer']].hist()

data_train[['Steel_Plate_Thickness']].hist()

data_train[['Edges_Index', 'Empty_Index', 'Square_Index']].hist()

data_train[['Edges_X_Index', 'Edges_Y_Index', 'Outside_X_Index']].hist()

data_train[['Outside_Global_Index']].hist()
plt.ylabel('Frecuencia')

data_train[['Log_X_Index', 'Log_Y_Index', 'LogOfAreas']].hist()

data_train[['Orientation_Index', 'Luminosity_Index', 'SigmoidOfAreas']].hist()

plt.ylabel('Frecuencia')

"""## Statistical summaries"""

# Estadisticos del dataset TRAIN
data_train.describe()

"""# Preproceesamiento

Volvemos a visualizar algunos datos, con sus columnas de los datasets TRAIN y TEST
"""

data_train.head(2)

data_test.head(2)

# Seleccionamos, de TRAIN, para X_train las columnas de los indices 1 a 27. (Se pone 28 porque toma las columnas en un intervalo abierto) 
# Mismo caso con y_train para las columnas 28 a 34 que pertenecen a los valores de las clases.
X_train, y_train = data_train[data_train.columns[1:28]], data_train[data_train.columns[28:35]]

# Seleccionamos para X_test las columnas de los indices 1 a 27 de TEST
X_test = np.array(data_test[data_test.columns[1:28]])


print(X_train.shape)  # 145 instancias, 27 variables
print(y_train.shape)  # 1455 instancias, 7 clases   <- Labels
print(X_test.shape)   # 485 instanias, 27 variables

X_train.head(2)

y_train.head(2)

"""# Desarrollo del Modelo de Machine Learning"""

# Librerias a utilizar
from sklearn.neural_network import MLPClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier

from sklearn.metrics import multilabel_confusion_matrix

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
X_train_norm = scaler.fit_transform(X_train)
X_test_norm = scaler.fit_transform(X_test)

# Creamos una lista con los nombres de cada clase, respetando el orden en que aparecen en las columnas del dataset original
classses = ['Pastry', 'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults']

def deploy_conf_matrix(confusion_matrix, classses, algoritmo):
  fig = plt.figure(figsize=(15,12))
  fig.suptitle(algoritmo, fontsize=20)
  # fig.subplots_adjust(wspace=.25, left=0.035, right=.985, top=.925, bottom=.1)

  for i, (label, matrix) in enumerate(zip(classses, confusion_matrix)):
    plt.subplot(f'33{i+1}')
    labels = [f'not_{label}', label]
    sns.heatmap(matrix, annot=True, square=True, fmt='d', cbar=False, cmap='Blues', xticklabels=labels, yticklabels=labels, linecolor='black', linewidths=1)
    plt.title(labels[0])

  plt.tight_layout()
  plt.show()

"""## KNN"""

# KNN, trabaja mejor con variables normalzadas entre 0 y 1
knn = KNeighborsClassifier(n_neighbors=3)
knn.fit(X_train_norm, y_train)
predict1 = knn.predict(X_train_norm)

confusion_matrix1 = multilabel_confusion_matrix(y_train, predict1)
deploy_conf_matrix(confusion_matrix1, classses, 'KNN 3')

"""## Multi-layer Perceptron"""

# Red Neuronal MLP, trabaja mejor con variables normalzadas entre 0 y 1
mlp = MLPClassifier(max_iter=300)
mlp.fit(X_train_norm, y_train)
predict2 = mlp.predict(X_train_norm)

confusion_matrix2 = multilabel_confusion_matrix(y_train, predict2)
deploy_conf_matrix(confusion_matrix2, classses, 'MLP')

"""## Arbol de Decision"""

# Arbol de Decision
decision_tree = DecisionTreeClassifier()
decision_tree.fit(X_train, y_train)

predict3 = decision_tree.predict(X_train)

confusion_matrix3 = multilabel_confusion_matrix(y_train, predict3)
deploy_conf_matrix(confusion_matrix3, classses, "Decision Tree")

"""## Evalucion de los modelos"""

from sklearn import metrics

evaluaciones = pd.DataFrame()

#Accuracy
evaluaciones.loc['KNN', 'Accuracy'] = metrics.accuracy_score(y_train, predict1)
evaluaciones.loc['MLP', 'Accuracy'] = metrics.accuracy_score(y_train, predict2)
evaluaciones.loc['DecisionTree','Accuracy'] = metrics.accuracy_score(y_train, predict3)

# Precision
evaluaciones.loc['KNN','Precision'] = metrics.precision_score(y_train, predict1, average='macro')
evaluaciones.loc['MLP','Precision'] = metrics.precision_score(y_train, predict2, average='macro')
evaluaciones.loc['DecisionTree','Precision'] = metrics.precision_score(y_train, predict3, average='macro')

# Recall
evaluaciones.loc['KNN','Recall'] = metrics.recall_score(y_train, predict1, average='macro')
evaluaciones.loc['MLP','Recall'] = metrics.recall_score(y_train, predict2, average='macro')
evaluaciones.loc['DecisionTree','Recall'] = metrics.recall_score(y_train, predict3, average='macro')

# f1
evaluaciones.loc['KNN','F1-score'] = metrics.f1_score(y_train, predict1, average='weighted')
evaluaciones.loc['MLP','F1-score'] = metrics.f1_score(y_train, predict2, average='weighted')
evaluaciones.loc['DecisionTree','F1-score',] = metrics.f1_score(y_train, predict3, average='weighted')

evaluaciones

"""# Predicciones con dataset TEST"""

predict1_test = knn.predict(X_test_norm)
predict2_test = mlp.predict(X_test_norm) 
predict3_test = decision_tree.predict(X_test)


df_knn_predicts = pd.DataFrame(predict1_test, columns=classses)
df_mlp_predicts = pd.DataFrame(predict2_test, columns=classses)
df_tree_predicts = pd.DataFrame(predict3_test, columns=classses)

df_tree_predicts

"""# Guardar las predicciones de TEST

**NOTA:** El archivo en formato tabla, con las clases concatenadas al final del archivo, siguiendo el formato del archivo TRAIN.
"""

# data_test = pd.read_csv('Faults.test', delimiter='\t')
data_test.head(2)

# Agregamos las prediciones hechas para los datos de TEST en el dataframe inicial "data_test" que es donde se guardó la informacion de TEST al inicio de la ejecucion
data_test[classses] = df_tree_predicts
data_test.head(2)

# with open('Faults_temp.test', 'w') as f:
#   for line in data_test:
#     f.write(line)
#     f.write('\n')
data_test.rename(columns={'Unnamed: 0':'\"\"'}, inplace=True)
data_test.to_csv('Faults_completed.test', header=True, index=None, sep='\t', mode='a')



"""# Extra

## Visualizacion del arbol de decision entrenado.
"""

plt.figure(figsize=(15,12))
sklearn.tree.plot_tree(decision_tree)
plt.show()

import graphviz

dot_data = sklearn.tree.export_graphviz(decision_tree, out_file=None) 
graph = graphviz.Source(dot_data) 
graph.render("Tecnoap_decision_tree")

"""## Feature Importance generado por el arbol de decision entrenado

"""

importance = pd.DataFrame({'feature': X_train.columns, 'importance' : np.round(decision_tree.feature_importances_, 4)})

importance.sort_values('importance', ascending=False, inplace = True)

print(importance)

"""# ****  **Solución y Justificación** ****

## Data Exploration & Cleaning
*   Se exploró el dataset para encontrar algun dato faltante, ademas se identifico que tipo de variable se registraban en el dataset.
*   Fué importante conocer el rango de las variables para detectar variables continuas y categoricas.
*   Se visualizó como estaban descritas de origen las etiqeutas que representaban la clase de cada instancia, se trabajaron como venian de origen, de forma multilabel.
*   Los histogramas fueron necesarios para conocer visualmente como era la distrubcion de los datos de cada variable.
*   Se obtuvo el registro estadistico de cada variable.

## Preprocesamiento

En este apartado se filtro de dataset TRAIN quitando el posible ID identificado en la fase de la exploracion de los datos, ademas de las etiquetas que representaban los datos.

Algo similar con el dataset TEST fue realizado. En este sólo se omitió la columna del ID.

También se llevó a cabo una normalizacion escalonada de estos datos para mejorar el desempeño de clasificación con los algoritmos KNN y la Red Neuronal, ya que estos son mas sensibles a trabajar con datos normalziados.

## Desarrollo del Modelo
*   Se propusieron tres experimentos diferentes, uno con un algoritmo de aprendizaje supervisado diferente: KNN, Red Neuronas de Segunda Generacion y Arbol de Decision.
*   Se planteó hacer la clasificacion con un algoritmo sencillo como lo es KNN, sin embargo no se tenian resultados buenos, por lo que se aplicó una Red Neuronal, pero al hacer 300 iteraciones, este modelo tampoco generaba buenos resultados.
*   El Arbol de Decision se prefirió utilizar dado a su gran alcance para separar el espacio de las variables. Este modelo generaba mejores resultados utilizando todas las variables independientes para clasificacion.

Se obtuvieron las matriz de confusión  para cada algoritmo, a partir de esta matriz, se obtuvieron las métricas para evaluar los algoritmos. Estas métricas son Accuracy, Precisiion Recall, F1-Score.

## Evaluacion de los modelos

Accuracy: La porcion de instancias que fueron correctamente clasificados.

Precision: La porcion de predicciones correctas entre todas las predicciones de una determinada clase.

Recall: La porcion de instancias de una determinada clase que han sido predichos por el modelo como pertenecientes a esa clase.

F1-score: Para una determinada clase, es la media armónica de su precision y su recall. Sirve como medida global de la calidad de las predicciones de un clasificador.


Teniendo en cuenta lo anterior, se observa que para la Red NEuronal (MLP) su rendimiento para clasificar patrones sin conocer es muy bajo en comparacion con KNN.


El rendimiento de estos dos algoritmos es entendible, dado a que el dataset TRAIN no estaba balanceado las clases. Por mencionar: 
* Other_Faults -> 500 registros
* Bumps        -> 302 registros
* Dirtiness    -> 42 registros
* Stains       -> 54 registros
* K_Scatch     -> 294 registros
* Z_Scratch    -> 145 registros  
* Pastry       -> 118 registros


Sin embargo, El Arbol de Decision, por sus caracteristicas de dividir el espacio de busqueda (en dos ramas, en este caso). Divide recursivamente los registros del conjunto de datos de entrenamiento en subconjutos de registros con valores similares para la variable objetivo. Se lleva a cabo una busqueda exhaustiva de todas las variables disponibles y de todos las divisiones posibes, seleccionado la division optima.


Con esto solventamos que TRAIN no este balanceado. Otra opcion era crear instancias artificiales de los datos existentes para incrementar las instancias por cada clase.



* La prediccion de la clase para cada instancia de TEST * se guarda en un archivo de text llamado "Faults_completed.test".


![image.png](data:image/png;base64,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)
"""